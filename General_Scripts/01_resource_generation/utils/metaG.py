def shorten_input(data_folder, analysis_folder):
    '''
    Filter large input containing all small genes predicted
    from metaG and leave just those predicted in AMPSphere 
    '''
    import pandas as pd

    ampsphere = f'{analysis_folder}/AMPsphere_GMSC_correspondence.tsv.gz'
    infile = f'{data_folder}/GMSC10.metag_smorfs.rename.txt.xz'
    ofile = f'{data_folder}/shortened_renaming.txt.gz'

    # retrieve genes
    data = pd.read_table(ampsphere, sep='\t', header='infer')
    gmsc_genes = []
    data['genes'] = [x.split(',') for x in data['genes']]
    for x in data['genes']: gmsc_genes += x
    gmsc_genes = set(gmsc_genes)
    
    for record in pd.read_table(infile,
                                sep='\t',
                                header='infer', 
                                chunksize=10_000_000):
        record = record[record['#GMSC_id'].isin(gmsc_genes)]
        record.to_csv(ofile,
                      mode='at',
                      sep='\t',
                      header=False,
                      index=None)

    
def format_geneinfo(prodigal_out): 
    '''
    Extracts information from a prodigal gene prediction line and returns a set of variables.

    Input:
    prodigal_out: tuple, contains 3 fields generated by pandas itertuples.
    
    Output:
    list, contains 13 fields.
    '''    
    try:
        gmsc, sample = prodigal_out[1], prodigal_out[2]
        contig = '_'.join(prodigal_out[3].split('_')[0:2])
        start, stop = prodigal_out[5], prodigal_out[7]
        strand = prodigal_out[9]
        amp = prodigal_out[12]
        prodigal_out_details = prodigal_out[11].split(';')
        fid = prodigal_out_details[0].replace('ID=', '')
        partial = prodigal_out_details[1].replace('partial=', '')
        start_type = prodigal_out_details[2].replace('start_type=', '')
        rbs_motif = prodigal_out_details[3].replace('rbs_motif=', '')
        rbs_spacer = prodigal_out_details[4].replace('rbs_spacer=', '')
        gc_cont = prodigal_out_details[5].replace('gc_cont=', '')

        return [amp, gmsc, sample,
                contig, start, stop, strand, 
                fid, partial, start_type,
                rbs_motif, rbs_spacer,
                float(gc_cont)]
    except IndexError as e:
        print(f"Index error occurred, input tuple length: {len(prodigal_out)}, error message: {e}")
        return None
        

def anno_metaG(data_folder, analysis_folder):
    import pandas as pd

    # Load the correspondence list
    corrlist = pd.read_table(f'{analysis_folder}/AMPsphere_GMSC_correspondence.tsv.gz', sep='\t')
    corrlist['genes'] = corrlist['genes'].apply(lambda x: x.split(','))

    dictresource = {}
    for index, row in corrlist.iterrows():
        for gene in row['genes']:
            dictresource[gene] = row['accession']

    columns = ['accession', 'gmsc', 'sample', 'contig', 'start', 'stop', 'strand', 'fid', 'partial', 'start_type', 'rbs_motif', 'rbs_spacer', 'gc_cont']
    newdf = pd.DataFrame(columns=columns)

    infile = f'{data_folder}/shortened_renaming.txt.gz'
    data_chunks = pd.read_table(infile, sep='\t', header=None, names=['gmsc', 'sample', 'original_header'], chunksize=500_000)

    for chunk in data_chunks:
        expanded_details = chunk['original_header'].str.extract(r'# (\d+) # (\d+) # (-?1) # ID=(.+?);partial=(.+?);start_type=(.+?);rbs_motif=(.+?);rbs_spacer=(.+?);gc_cont=(\d+\.\d+)')
        expanded_details.columns = ['start', 'stop', 'strand', 'fid', 'partial', 'start_type', 'rbs_motif', 'rbs_spacer', 'gc_cont']
        chunk = pd.concat([chunk.drop(columns=['original_header']), expanded_details], axis=1)

        # Convert the dataframe into the correct format
        chunk['accession'] = chunk['gmsc'].map(dictresource)
        newdf = pd.concat([newdf, chunk], ignore_index=True)

    # Save the modified dataframe
    ofile = f'{analysis_folder}/AMPsphere_metaG_annotation.tsv.gz'
    newdf.to_csv(ofile, sep='\t', header=True, index=False)
    print(f"Data written to {ofile}")




def origins(data_folder, analysis_folder):
    '''
    Annotate AMPs origins discriminating if it comes from
    metagenomes, progenomes, and their genes
    '''
    import pandas as pd
    
    # inputs
    corrlist = f'{analysis_folder}/AMPsphere_GMSC_correspondence.tsv.gz' 
    progenomes = f'{analysis_folder}/AMPsphere_proGenomes_correspondence.tsv.gz'
    metagenomes = f'{analysis_folder}/AMPsphere_metaG_annotation.tsv.gz'
    # outputs
    species_out = f'{analysis_folder}/AMPSphere_v.2022-03.species.tsv.gz'
    origin_file = f'{analysis_folder}/AMPSphere_v.2022-03.origin_samples.tsv.gz'

    # processing gmsc genes
    gmsc = pd.read_table(corrlist, sep='\t', header='infer')

    # processing progenomes
    data = pd.read_table(progenomes, sep='\t', header='infer')
    data[['accession',
          'genome',
          'specI']].to_csv(species_out, 
                           sep='\t', header=True, index=None)

    progenomes = dict()
    for record in data.groupby('accession'):
        progenomes[record[0]] = ','.join(record[1].genome.tolist())

    progenomes = pd.DataFrame.from_dict(progenomes,
                                        orient='index',
                                        columns=['progenomes'])
                                        
    progenomes = progenomes.reset_index()
    progenomes = progenomes.rename({'index': 'accession'},
                                   axis=1)

    # processing metagenomes
    data = pd.read_table(metagenomes, sep='\t', header='infer')
    metagenomes = dict()
    for record in data.groupby('accession'):
        metagenomes[record[0]] = ','.join(record[1]['sample'].tolist())
    
    metagenomes = pd.DataFrame.from_dict(metagenomes,
                                         orient='index',
                                         columns=['metagenomes'])
                                        
    metagenomes = metagenomes.reset_index()
    metagenomes = metagenomes.rename({'index': 'accession'},
                                     axis=1)
    
    # merging
    gmsc = gmsc.merge(on='accession', right=progenomes, how='outer')
    gmsc = gmsc.merge(on='accession', right=metagenomes, how='outer')
    
    gmsc = gmsc[['accession', 'genes', 'progenomes', 'metagenomes']]
    
    gmsc.to_csv(origin_file, 
                sep='\t',
                header=True,
                index=None)


def assoc_metadata(data_folder, analysis_folder):
    '''
    Associate metadata to the AMPSphere info
    '''
    import pandas as pd
    from collections import Counter
    
    # inputs
    metagenomes = f'{analysis_folder}/AMPsphere_metaG_annotation.tsv.gz'
    metadata = f'{data_folder}/metadata.tsv.xz'

    # outputs
    host_out = f'{analysis_folder}/AMPSphere_v.2022-03.hosts.tsv.gz'
    location_out = f'{analysis_folder}/AMPSphere_v.2022-03.locations.tsv.gz'
    microont_out = f'{analysis_folder}/AMPSphere_v.2022-03.microontology.tsv.gz'

    # load metagenomes
    metagenomes = pd.read_table(metagenomes, sep='\t', header='infer')
    metagenomes = metagenomes[['accession', 'sample']]
    
    # load metadata
    metadata = pd.read_table(metadata, sep='\t', header='infer')
    metadata = metadata.rename({'sample_accession': 'sample'}, axis=1)
    metadata = metadata[['sample',
                         'microontology',
                         'geographic_location',
                         'latitude',
                         'longitude',
                         'environment_material',
                         'host_common_name',
                         'host_scientific_name',
                         'host_tax_id']]

    # merge
    metagenomes = metagenomes.merge(on='sample', right=metadata)
    
    # microontology
    micro = metagenomes[['accession',
                         'microontology']]
    
    micro = micro.pivot_table(index=['accession',
                                     'microontology'],
                              aggfunc='size')

    micro = micro.reset_index()
    micro = micro.rename({0: 'counts'},
                         axis=1)                              
                         
    micro.to_csv(microont_out,
                 sep='\t',
                 header=True,
                 index=None)    

    # geoloc
    geoloc = metagenomes[['accession',
                          'geographic_location']]
    
    geoloc = geoloc.pivot_table(index=['accession',
                                       'geographic_location'],
                                aggfunc='size')
                                
    geoloc = geoloc.reset_index()
    geoloc = geoloc.rename({0: 'counts'},
                         axis=1)                              

    geoloc.to_csv(location_out,
                  sep='\t',
                  header=True,
                  index=None)    

    # host_out
    host = metagenomes[['accession',
                        'host_common_name',
                        'host_scientific_name',
                        'host_tax_id']]

    host = host.dropna()                    
    host = host.pivot_table(index=['accession',
                                   'host_common_name',
                                   'host_scientific_name',
                                   'host_tax_id'],
                            aggfunc='size')
                            
    host = host.reset_index()
    host = host.rename({0: 'counts'},
                       axis=1)                              

    host.to_csv(host_out,
                sep='\t',
                header=True,
                index=None)


def metag():
    import os
    
    data_folder = 'data/'
    analysis_folder = 'analysis/'
    
    # Ensure the directories exist
    for f in [data_folder, analysis_folder]:
        os.makedirs(f, exist_ok=True)

    print('Filtering the original GMSC large file')
    shorten_input(data_folder, analysis_folder)
    print('Working on the filtered subset')
    try:
        anno_metaG(data_folder, analysis_folder)
    except Exception as e:
        print('Error processing metagenomic data:', e)
    print('Generating file with AMP origins')
    origins(data_folder, analysis_folder)
    print('Associating AMPs with metadata')
    assoc_metadata(data_folder, analysis_folder)

